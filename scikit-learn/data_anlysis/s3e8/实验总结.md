# 1.Test_6_3mobilenet_use_simam
## 1.1 Time
valid epoch[70/70]��loss: 0.003.acc:0.977
Finished Training
5308.811608314514
## 1.2 configuration information
1. optimizer = torch.optim.SGD(model.parameters(), lr=0.1momentum=0.9, weight_decay=4E-5)
2. batch_size = 32
3. epochs = 70
4. parser.add_argument('--lr', type=float, default=0.1)
5. parser.add_argument('--lrf', type=float, default=0.01)
## 1.3 revisement
添加了一个simam注意力结构块，并且没有取消掉GroupConvlution。
## 1.4 accuracy valid
[0.3127413127413127, 0.20463320463320464, 0.4527027027027027, 0.5241312741312741, 0.4362934362934363, 0.5521235521235521, 0.5125482625482626, 0.612934362934363, 0.5907335907335908, 0.583976833976834, 0.7007722007722008, 0.6158301158301158, 0.696911196911197, 0.5463320463320464, 0.6003861003861004, 0.7644787644787645, 0.7442084942084942, 0.724903474903475, 0.7519305019305019, 0.7808880308880309, 0.8194980694980695, 0.8783783783783784, 0.7596525096525096, 0.8416988416988417, 0.8513513513513513, 0.6486486486486487, 0.8764478764478765, 0.8416988416988417, 0.8938223938223938, 0.8474903474903475, 0.8976833976833977, 0.8947876447876448, 0.888030888030888, 0.9063706563706564, 0.9295366795366795, 0.918918918918919, 0.9111969111969112, 0.9353281853281853, 0.944015444015444, 0.946911196911197, 0.9333976833976834, 0.9652509652509652, 0.9488416988416989, 0.9420849420849421, 0.9555984555984556, 0.9642857142857143, 0.9671814671814671, 0.9691119691119691, 0.9691119691119691, 0.9768339768339769, 0.9691119691119691, 0.9758687258687259, 0.9768339768339769, 0.971042471042471, 0.972007722007722, 0.972007722007722, 0.974903474903475, 0.9777992277992278, 0.9768339768339769, 0.9768339768339769, 0.9758687258687259, 0.9777992277992278, 0.972972972972973, 0.9758687258687259, 0.9758687258687259, 0.974903474903475, 0.9758687258687259, 0.9768339768339769, 0.9777992277992278, 0.9768339768339769]
## 1.5 data distribution
训练集和测试集的分布保持不变



# 1.Test_6_4mobilenet_use_cbam

## 1.1 Time
valid epoch[90/90]，loss: 0.003.acc:0.976
Finished Training
5195.661161661148
## 1.2 configuration information
1. optimizer = torch.optim.SGD(model.parameters(), lr=0.1momentum=0.9, weight_decay=4E-5)
2. batch_size = 32
3. epochs = 90
4. parser.add_argument('--lr', type=float, default=0.1)
5. parser.add_argument('--lrf', type=float, default=0.01)
## 1.3 revisement
添加了一个simam注意力结构块，并且取消掉GroupConvlution。
## 1.4 accuracy valid
[0.24613899613899615, 0.32432432432432434, 0.4874517374517375, 0.38513513513513514, 0.3735521235521235, 0.5183397683397684, 0.5617760617760618, 0.4768339768339768, 0.43532818532818535, 0.5328185328185329, 0.5067567567567568, 0.7142857142857143, 0.6563706563706564, 0.5646718146718147, 0.6747104247104247, 0.7837837837837838, 0.7133204633204633, 0.6476833976833977, 0.7326254826254827, 0.6457528957528957, 0.752895752895753, 0.8281853281853282, 0.8088803088803089, 0.8011583011583011, 0.8185328185328186, 0.8262548262548263, 0.803088803088803, 0.833976833976834, 0.9073359073359073, 0.8861003861003861, 0.8561776061776062, 0.8918918918918919, 0.8648648648648649, 0.8793436293436293, 0.8803088803088803, 0.888030888030888, 0.8677606177606177, 0.8445945945945946, 0.8687258687258688, 0.9140926640926641, 0.8484555984555985, 0.9314671814671814, 0.9054054054054054, 0.9295366795366795, 0.918918918918919, 0.9420849420849421, 0.888030888030888, 0.917953667953668, 0.8677606177606177, 0.9401544401544402, 0.9420849420849421, 0.9411196911196911, 0.944015444015444, 0.9662162162162162, 0.9411196911196911, 0.971042471042471, 0.9536679536679536, 0.9555984555984556, 0.9633204633204633, 0.971042471042471, 0.9613899613899614, 0.9700772200772201, 0.971042471042471, 0.9739382239382239, 0.9691119691119691, 0.9700772200772201, 0.9700772200772201, 0.972007722007722, 0.9662162162162162, 0.974903474903475, 0.9758687258687259, 0.9758687258687259, 0.9758687258687259, 0.9777992277992278, 0.971042471042471, 0.9691119691119691, 0.972972972972973, 0.974903474903475, 0.974903474903475, 0.974903474903475, 0.9739382239382239, 0.974903474903475, 0.9739382239382239, 0.974903474903475, 0.974903474903475, 0.974903474903475, 0.9758687258687259, 0.9758687258687259, 0.9768339768339769, 0.9758687258687259]
## 1.5 data distribution
训练集和测试集的分布保持不变




# 1.Test_6_5mobilenet_use_se_simam

## 1.1 Time
valid epoch[90/90]，loss: 0.003.acc:0.976
Finished Training
5195.661161661148
## 1.2 configuration information
1. optimizer = torch.optim.SGD(model.parameters(), lr=0.1momentum=0.9, weight_decay=4E-5)
2. batch_size = 32
3. epochs = 90
4. parser.add_argument('--lr', type=float, default=0.1)
5. parser.add_argument('--lrf', type=float, default=0.01)
## 1.3 revisement
将原来版本中的se模块取消掉，更换为simam模块，并且取消掉GroupConvlution。
## 1.4 accuracy valid
[0.15733590733590733, 0.2577220077220077, 0.38996138996138996, 0.3696911196911197, 0.4826254826254826, 0.5511583011583011, 0.6013513513513513, 0.4951737451737452, 0.6805019305019305, 0.6061776061776062, 0.5415057915057915, 0.7895752895752896, 0.7712355212355212, 0.7654440154440154, 0.63996138996139, 0.7335907335907336, 0.6621621621621622, 0.7065637065637066, 0.803088803088803, 0.805984555984556, 0.8494208494208494, 0.8745173745173745, 0.8484555984555985, 0.7355212355212355, 0.8166023166023166, 0.8822393822393823, 0.888030888030888, 0.8542471042471043, 0.861969111969112, 0.9025096525096525, 0.9025096525096525, 0.88996138996139, 0.861003861003861, 0.9227799227799228, 0.8368725868725869, 0.9343629343629344, 0.9121621621621622, 0.9054054054054054, 0.9044401544401545, 0.916023166023166, 0.9218146718146718, 0.9498069498069498, 0.9034749034749034, 0.9478764478764479, 0.943050193050193, 0.9295366795366795, 0.916988416988417, 0.9517374517374517, 0.9256756756756757, 0.9594594594594594, 0.9662162162162162, 0.9391891891891891, 0.9546332046332047, 0.9633204633204633, 0.9459459459459459, 0.9671814671814671, 0.9565637065637066, 0.9662162162162162, 0.974903474903475, 0.9565637065637066, 0.9700772200772201, 0.9623552123552124, 0.9652509652509652, 0.9662162162162162, 0.972007722007722, 0.9681467181467182, 0.972007722007722, 0.971042471042471, 0.9671814671814671, 0.971042471042471, 0.972972972972973, 0.972972972972973, 0.972972972972973, 0.9739382239382239, 0.972007722007722, 0.972007722007722, 0.9739382239382239, 0.971042471042471, 0.971042471042471, 0.971042471042471, 0.972007722007722, 0.972972972972973, 0.972007722007722, 0.972007722007722, 0.972007722007722, 0.971042471042471, 0.971042471042471, 0.971042471042471, 0.971042471042471, 0.972007722007722]
## 1.5 data distribution
训练集和测试集的分布保持不变

# 1.Test_6_5mobilenet_use_se_simam

## 1.1 Time
valid epoch[90/90]，loss: 0.003.acc:0.976
Finished Training
5195.661161661148
## 1.2 configuration information
1. optimizer = torch.optim.SGD(model.parameters(), lr=0.1momentum=0.9, weight_decay=4E-5)
2. batch_size = 32
3. epochs = 90
4. parser.add_argument('--lr', type=float, default=0.1)
5. parser.add_argument('--lrf', type=float, default=0.01)
## 1.3 revisement
添加了一个simam注意力结构块，并且取消掉GroupConvlution。
## 1.4 accuracy valid

## 1.5 data distribution
训练集和测试集的分布保持不变

